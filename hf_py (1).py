# -*- coding: utf-8 -*-
"""hf.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y_DkKwyvqyYYstqvWKic4C-VfpWCiCjK
"""

#from langchain_core.output_parsers import StrOutputParser
from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint
#from langchain_core.prompts import PromptTemplate
import streamlit as st




api_key="hf_................."

def bot(api_key):

  llm=HuggingFaceEndpoint(
      repo_id="google/gemma-2-2b-it",
      task="text-generation",
      huggingfacehub_api_token=api_key
  )
  model=ChatHuggingFace(
      llm=llm,
      verbose=True
  )
  return model
def template():
    return PromptTemplate(
        input_variables=["user_query"],
        template="""
You are a world-class expert in Generative AI, including large language models (LLMs), diffusion models, GANs, VAEs, multimodal AI systems, prompt engineering, fine-tuning, RLHF, and model deployment. You have extensive research and practical experience in building, training, evaluating, and deploying generative AI models across multiple domains (text, image, audio, video, and 3D).

Your responses should always be:
1. Highly detailed and technically accurate.
2. Include step-by-step explanations, examples, and diagrams if necessary.
3. Provide best practices and recommendations for real-world implementation.
4. Explain complex concepts in a clear, beginner-friendly manner while retaining technical depth.
5. Include references to relevant papers, frameworks, or libraries whenever applicable.
6. Anticipate follow-up questions and clarify common misunderstandings.

Always assume the reader wants to learn deeply, and structure your answers as if you are teaching a workshop or writing an expert-level guide.

User Query: {user_query}
"""
    )

st.header("chat bot")
st.subheader("ask the Question")
query=st.text_input("Enter the question")
if query:
  model=bot()

  prompt = template()
  formatted_prompt = prompt.format(user_query=query)


response = model.invoke(formatted_prompt)
st.subheader("response")
st.session_state=[]


st.write(response if isinstance(response, str) else response.content)

if 'response' not  in session_state:
  st.session_state['response']=[]
if 'response' not in st.session_state['response']:
  st.session_state.append(response)
